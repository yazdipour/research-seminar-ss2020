{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /data/shya6478/fixed/data1.json_156: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! ls /data/shya6478/fixed/data1.json_156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory '/data/shya6478/fixed-prep/': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir /data/shya6478/fixed-prep/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "str_to_obj = lambda s: ast.literal_eval(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(fileindex):\n",
    "    motherdf = pd.DataFrame(columns=['tweet_id', 'tweet_text', 'tweet_tags', 'tweet_created_at',\n",
    "       'tweet_reply_count', 'tweet_in_reply_to_status_id',\n",
    "       'tweet_in_reply_to_user_id', 'place_id', 'place_country', 'place_name',\n",
    "       'user_id', 'user_name', 'user_friends_count', 'user_favourites_count',\n",
    "       'user_created_at', 'user_verified', 'user_statuses_count',\n",
    "       'user_followers_count', 'user_default_profile_image'])\n",
    "    fldr = f'/data/shya6478/07/{fileindex}/'\n",
    "    for filename in os.listdir(fldr):\n",
    "        path = fldr+filename\n",
    "        df = pd.read_csv(path,lineterminator='\\n')\n",
    "        # prepare\n",
    "        for index, t in df.iterrows():\n",
    "            processed = processed_tweet(t, index)\n",
    "            row = create_clean_twt(t, processed)\n",
    "            motherdf = motherdf.append(row,ignore_index=True)\n",
    "    motherdf.to_csv(f'/data/shya6478/fixed-prep/data{fileindex}.csv')\n",
    "    print(f'$$$ Saved#/data{fileindex}.csv')\n",
    "    return\n",
    "# df[df['in_reply_to_user_id'].notna()].to_csv('/data/shya6478/only_rpl.csv', single_file = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor\n",
    "clean_place = lambda pl: {'id': pl['id'], 'country': pl['country_code'], 'name': pl['name']}\n",
    "def clean_user(u):\n",
    "    u = str_to_obj(u)\n",
    "    wanted_keys = ('id',\n",
    "                   'screen_name',\n",
    "                   'friends_count',\n",
    "                   'favourites_count',\n",
    "                   'created_at',\n",
    "                   'verified',\n",
    "                   'statuses_count',\n",
    "                   'followers_count')\n",
    "    del_keys = u.keys()-wanted_keys\n",
    "    del_values = [u.pop(k) for k in del_keys]\n",
    "    return u\n",
    "def clean_tweet(text): \n",
    "    t=text.lower()\n",
    "    tags = preprocessor.parse(t).hashtags\n",
    "    if tags is not None: \n",
    "        tags=[tg.match for tg in preprocessor.parse(t).hashtags]\n",
    "    return {'text':preprocessor.clean(t), 'tags':tags}\n",
    "def processed_tweet(t,inx):\n",
    "    twt = clean_tweet(t['text'])\n",
    "    usr = clean_user(t['user'])\n",
    "    try:\n",
    "        plc = clean_place(str_to_obj(t['place']))\n",
    "    except:\n",
    "        plc = {'id': None, 'country': None, 'name':None }\n",
    "    return {'text':twt['text'], 'tags':twt['tags'], 'user':usr, 'place':plc} #, 'sentiment': sentiment(twt['text'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_twt(t, processed):\n",
    "    return {\n",
    "        'tweet_id':t['id'],\n",
    "        'tweet_text':processed['text'],\n",
    "        'tweet_tags':processed['tags'],\n",
    "        'tweet_created_at':t['created_at'],\n",
    "        'tweet_in_reply_to_status_id':t['in_reply_to_status_id'],\n",
    "        'tweet_in_reply_to_user_id':t['in_reply_to_user_id'],\n",
    "        'place_id':processed['place']['id'],\n",
    "        'place_country':processed['place']['country'],\n",
    "        'place_name':processed['place']['name'],\n",
    "        'user_id':processed['user']['id'],\n",
    "        'user_name':processed['user']['screen_name'],\n",
    "        'user_friends_count':processed['user']['friends_count'],\n",
    "        'user_favourites_count':processed['user']['favourites_count'],\n",
    "        'user_created_at':processed['user']['created_at'],\n",
    "        'user_verified':processed['user']['verified'],\n",
    "        'user_statuses_count':processed['user']['statuses_count'],\n",
    "        'user_followers_count':processed['user']['followers_count']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def prepdask(fileindex):\n",
    "    motherdf = pd.DataFrame(columns=['tweet_id','tweet_text', 'tweet_tags', 'tweet_created_at', 'tweet_in_reply_to_status_id',\n",
    "       'tweet_in_reply_to_user_id', 'place_id', 'place_country', 'place_name',\n",
    "       'user_id', 'user_name', 'user_friends_count', 'user_favourites_count',\n",
    "       'user_created_at', 'user_verified', 'user_statuses_count',\n",
    "       'user_followers_count'])\n",
    "    fldr = f'/data/shya6478/fixed/{fileindex}/*'\n",
    "    df = dd.read_csv(fldr,lineterminator='\\n')\n",
    "    part = 1\n",
    "    # prepare\n",
    "    for index, t in df.iterrows():\n",
    "        if index==0:print(str(fileindex), end=',')\n",
    "        processed = processed_tweet(t, index)\n",
    "        row = create_clean_twt(t, processed)\n",
    "        motherdf = motherdf.append(row,ignore_index=True)\n",
    "        if len(motherdf.index) > 100000:\n",
    "            part = part + 1\n",
    "            motherdf.to_csv(f'/data/shya6478/fixed-prep/data{fileindex}-part{part}.csv')\n",
    "            print(f'$$$ Saved /data{fileindex}-part{part}.csv')\n",
    "            motherdf.drop(motherdf.index, inplace=True)\n",
    "    motherdf.to_csv(f'/data/shya6478/fixed-prep/data{fileindex}.csv')\n",
    "#     motherdf.to_feather(f'/data/shya6478/prep/data{fileindex}.ftr')\n",
    "    print(f'$$$ Saved#/data{fileindex}.ftr')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting p#10\n",
      "11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,$$$ Saved#/data11.ftr\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "for i in [10]:#range(12):\n",
    "    print(f'starting p#{i}')\n",
    "#     Process(target=prepdask, args=(i,)).start()\n",
    "    Thread(target=prepdask, args=(i+1, )).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
